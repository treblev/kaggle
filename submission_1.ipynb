{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost, pandas as pd\n",
    "import duckdb as db \n",
    "from xgboost import plot_importance, plot_tree\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np \n",
    "\n",
    "def calculate_rmsle(y_true, y_pred):\n",
    "    if (y_true < 0).any() or (y_pred < 0).any():\n",
    "        raise ValueError(\"RMSLE cannot be computed when true or predicted values are negative.\")\n",
    "    \n",
    "    # Calculate the Mean Squared Logarithmic Error (MSLE)\n",
    "    msle = mean_squared_log_error(y_true, y_pred)\n",
    "    \n",
    "    # Calculate the Root Mean Squared Logarithmic Error (RMSLE)\n",
    "    rmsle = np.sqrt(msle)\n",
    "    \n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holidays, df_stores, df_transactions, df_oil = pd.read_csv('data/holidays_events.csv'), pd.read_csv('data/stores.csv'), pd.read_csv('data/transactions.csv'), pd.read_csv('data/oil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_hols_count = db.sql(\"\"\"\n",
    "with cte as (\n",
    "  select * , month(date::datetime) \"month\", year(date::datetime) \"year\", week(date::datetime) \"week\" from df_holidays\n",
    ") , hols_count as (\n",
    "select distinct year, week, count(type) OVER (partition by year, week ORDER BY week ASC) \"number_of_holidays\" from cte \n",
    "), final_hols_count as (\n",
    "select  distinct year, week, avg(number_of_holidays ) OVER (PARTITION BY year, week) \"number_of_holidays\" FROM hols_count \n",
    ") \n",
    "select * from final_hols_count\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>7d_transactions_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>11</td>\n",
       "      <td>3547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>11</td>\n",
       "      <td>2675</td>\n",
       "      <td>3547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>11</td>\n",
       "      <td>2515</td>\n",
       "      <td>3111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>11</td>\n",
       "      <td>3052</td>\n",
       "      <td>2912.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>11</td>\n",
       "      <td>3188</td>\n",
       "      <td>2947.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83483</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>41</td>\n",
       "      <td>1316</td>\n",
       "      <td>1178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83484</th>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>41</td>\n",
       "      <td>1254</td>\n",
       "      <td>1206.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83485</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>41</td>\n",
       "      <td>1346</td>\n",
       "      <td>1223.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83486</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>41</td>\n",
       "      <td>1045</td>\n",
       "      <td>1222.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83487</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>41</td>\n",
       "      <td>1003</td>\n",
       "      <td>1160.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83488 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store_nbr  transactions  7d_transactions_avg\n",
       "0      2013-01-02         11          3547                  NaN\n",
       "1      2013-01-03         11          2675          3547.000000\n",
       "2      2013-01-04         11          2515          3111.000000\n",
       "3      2013-01-05         11          3052          2912.333333\n",
       "4      2013-01-06         11          3188          2947.250000\n",
       "...           ...        ...           ...                  ...\n",
       "83483  2017-08-11         41          1316          1178.000000\n",
       "83484  2017-08-12         41          1254          1206.500000\n",
       "83485  2017-08-13         41          1346          1223.625000\n",
       "83486  2017-08-14         41          1045          1222.500000\n",
       "83487  2017-08-15         41          1003          1160.625000\n",
       "\n",
       "[83488 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_csv('data/transactions.csv')\n",
    "df_transactions = db.sql(\"\"\"\n",
    "    select *, avg(transactions) OVER (partition by store_nbr order by date ROWS BETWEEN 8 PRECEDING AND 1 PRECEDING) \"7d_transactions_avg\" from df_transactions \n",
    "\"\"\").to_df()\n",
    "df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>7d_avg_oil_price</th>\n",
       "      <th>15d_avg_oil_price</th>\n",
       "      <th>90d_avg_oil_price</th>\n",
       "      <th>oil_lag364</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.14</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.97</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>93.140000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.083333</td>\n",
       "      <td>93.083333</td>\n",
       "      <td>93.083333</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.092500</td>\n",
       "      <td>93.092500</td>\n",
       "      <td>93.092500</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>47.65</td>\n",
       "      <td>47.901250</td>\n",
       "      <td>47.953750</td>\n",
       "      <td>46.751429</td>\n",
       "      <td>47.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>46.40</td>\n",
       "      <td>47.783750</td>\n",
       "      <td>47.881250</td>\n",
       "      <td>46.730220</td>\n",
       "      <td>46.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>46.46</td>\n",
       "      <td>47.510000</td>\n",
       "      <td>47.730625</td>\n",
       "      <td>46.694725</td>\n",
       "      <td>46.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>45.96</td>\n",
       "      <td>47.393750</td>\n",
       "      <td>47.583750</td>\n",
       "      <td>46.659890</td>\n",
       "      <td>44.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>47.26</td>\n",
       "      <td>47.182500</td>\n",
       "      <td>47.481875</td>\n",
       "      <td>46.634286</td>\n",
       "      <td>43.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  dcoilwtico  7d_avg_oil_price  15d_avg_oil_price  \\\n",
       "0    2013-01-01       93.14          0.000000           0.000000   \n",
       "1    2013-01-02       93.14         93.140000          93.140000   \n",
       "2    2013-01-03       92.97         93.140000          93.140000   \n",
       "3    2013-01-04       93.12         93.083333          93.083333   \n",
       "4    2013-01-05       93.12         93.092500          93.092500   \n",
       "...         ...         ...               ...                ...   \n",
       "1699 2017-08-27       47.65         47.901250          47.953750   \n",
       "1700 2017-08-28       46.40         47.783750          47.881250   \n",
       "1701 2017-08-29       46.46         47.510000          47.730625   \n",
       "1702 2017-08-30       45.96         47.393750          47.583750   \n",
       "1703 2017-08-31       47.26         47.182500          47.481875   \n",
       "\n",
       "      90d_avg_oil_price  oil_lag364  \n",
       "0              0.000000        0.00  \n",
       "1             93.140000        0.00  \n",
       "2             93.140000        0.00  \n",
       "3             93.083333        0.00  \n",
       "4             93.092500        0.00  \n",
       "...                 ...         ...  \n",
       "1699          46.751429       47.64  \n",
       "1700          46.730220       46.97  \n",
       "1701          46.694725       46.32  \n",
       "1702          46.659890       44.68  \n",
       "1703          46.634286       43.17  \n",
       "\n",
       "[1704 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oil = pd.read_csv('data/oil.csv')\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df_oil.set_index('date', inplace=True)\n",
    "# Create a date range that covers the entire period of the dataset\n",
    "date_range = pd.date_range(start=df_oil.index.min(), end=df_oil.index.max(), freq='D')\n",
    "df_oil = df_oil.reindex(date_range, method='ffill')\n",
    "df_oil['dcoilwtico']= df_oil['dcoilwtico'].bfill()\n",
    "df_oil.reset_index(inplace=True)\n",
    "df_oil.rename(columns={'index':'date'}, inplace=True)\n",
    "df_oil = db.sql(\"\"\"\n",
    "    select *, avg(dcoilwtico) OVER (ORDER BY date ROWS BETWEEN 8 PRECEDING AND 1 PRECEDING) \"7d_avg_oil_price\"\n",
    "    , avg(dcoilwtico) OVER (ORDER BY date ROWS BETWEEN 16 PRECEDING AND 1 PRECEDING) \"15d_avg_oil_price\"\n",
    "    , avg(dcoilwtico) OVER (ORDER BY date ROWS BETWEEN 91 PRECEDING AND 1 PRECEDING) \"90d_avg_oil_price\" \n",
    "    from df_oil \n",
    "\"\"\").df().fillna(0)\n",
    "df_oil = db.sql(\"\"\"\n",
    "  select *, coalesce(lag(dcoilwtico, 364) OVER (order by date),0) \"oil_lag364\"\n",
    "       from df_oil order  by date\n",
    "\"\"\").df()\n",
    "df_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_data(df):\n",
    "    df = df.sort_values(['id'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['day_of_week'] = df['date'].dt.day_of_week\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df[\"quarter\"] = df['date'].dt.quarter\n",
    "    df[\"weekofyear\"] = df['date'].dt.isocalendar().week \n",
    "    df['payday'] = df['date'].apply(lambda x: 1 if (pd.to_datetime(x).day==15 or pd.to_datetime(x).is_month_end) else 0)\n",
    "    df[\"is_weekend\"] = df['day_of_week'].apply(lambda x: 1 if (x in (4,5,6)) else 0) \n",
    "    #df_train['day_name'] = df_train['date'].dt.day_name()\n",
    "    df = db.sql(\"\"\"   \n",
    "        select distinct df.*  exclude sales\n",
    "        , case when (h.type='Event' and description like 'Terremoto Manabi%' and family='BEVERAGES') then 3115\n",
    "        when (h.type='Event' and description like 'Terremoto Manabi%' and family='GROCERY I') then 4325 \n",
    "        when (h.type='Event' and description like 'Terremoto Manabi%' and family='CLEANING') then 1150 \n",
    "        else sales \n",
    "        end \"sales\"  \n",
    "        , s.cluster , s.type, s.state , s.city \n",
    "        , case when h.transferred='False' THEN  COALESCE(h.type, 'Work Day') ELSE 'Work Day' END \"holiday_type\"\n",
    "        , o.dcoilwtico \"oil_price\",    \"7d_avg_oil_price\",\t\"90d_avg_oil_price\", \"15d_avg_oil_price\", oil_lag364\n",
    "        , t.\"7d_transactions_avg\"\n",
    "        , \"number_of_holidays\" \n",
    "        , case when h.locale = 'National' THEN 1 ELSE 0 END \"is_national_holiday\" \n",
    "        , case when (h.type='Event' and description like 'Terremoto Manabi%') THEN '1' ELSE 0 END \"earthquake_impact\"    \n",
    "        from df  \n",
    "        left join df_transactions t on df.date = t.date and df.store_nbr = t.store_nbr\n",
    "        left join df_holidays h on h.date = df.date\n",
    "        left join df_final_hols_count on df.weekofyear = df_final_hols_count.week and df.year=df_final_hols_count.year\n",
    "        left join df_oil o on o.date = df.date                \n",
    "        left join df_stores s on s.store_nbr = df.store_nbr \n",
    "        order by id \n",
    "    \"\"\").df()\n",
    "    #df_train['oil_price'] = df_train['oil_price'].ffill()\n",
    "    #df_train['oil_price'] = df_train['oil_price'].bfill()\n",
    "    df[\"onpromotion\"] = df[\"onpromotion\"].astype(np.int32)\n",
    "    df['oil_price'] = df['oil_price'].astype(np.float32) \n",
    "    df['sales'] = df['sales'].astype(np.float32) \n",
    "    df['year']= df['year'].astype(np.int32)\n",
    "    df['month']= df['month'].astype(np.int32)\n",
    "    df['day_of_week']= df['day_of_week'].astype(np.int16)\n",
    "    df['day_of_month'] = df['day_of_month'].astype(np.int16)\n",
    "    df['weekofyear']= df['weekofyear'].astype(np.int16)\n",
    "    df[\"family\"] = df[\"family\"].astype('category')\n",
    "    df[\"onpromotion\"] = df[\"onpromotion\"].astype('category')\n",
    "    df[\"type\"] = df[\"type\"].astype('category')\n",
    "    df[\"cluster\"] = df[\"cluster\"].astype('category')\n",
    "    df[\"holiday_type\"] = df[\"holiday_type\"].astype('category')\n",
    "    df[\"is_holiday\"] = df[\"holiday_type\"].apply(lambda x: 1 if x=='Holiday' else 0)\n",
    "    df[\"store_nbr\"] = df[\"store_nbr\"].astype('category')\n",
    "    df[\"city\"] = df[\"city\"].astype('category')\n",
    "    df[\"is_weekend\"] = df[\"is_weekend\"].astype('category')\n",
    "    return df \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_data(df):\n",
    "    df = db.sql(\"\"\"\n",
    "    with cte as (\n",
    "    select *\n",
    "    , avg(sales) OVER (PARTITION BY store_nbr, family, day_of_week ORDER BY \"date\" ASC ROWS BETWEEN 4 PRECEDING AND 1 PRECEDING) AS \"W3_rolling_mean_sales_store_family_dayofweek\"\n",
    "    from df \n",
    "    ) \n",
    "    select * \n",
    "    from cte -- where store_nbr==1 and family=='BEVERAGES'\n",
    "    \"\"\").df()\n",
    "    df = db.sql(\"\"\"\n",
    "    select *\n",
    "    , avg(sales) OVER (PARTITION BY store_nbr, family ORDER BY \"date\" ASC ROWS BETWEEN 8 PRECEDING AND 1 PRECEDING) \"D7_rolling_mean_sales_store_family\"\n",
    "    , avg(sales) OVER (PARTITION BY store_nbr, family ORDER BY \"date\" ASC ROWS BETWEEN 16 PRECEDING AND 1 PRECEDING) \"15D_rolling_mean_sales_store_family\"\n",
    "    from df     \n",
    "    \"\"\").df()\n",
    "    df = db.sql(\"\"\"\n",
    "    select * \n",
    "    , lag(D7_rolling_mean_sales_store_family, 364) OVER (PARTITION BY store_nbr, family order by date asc) \"lag1_7D_rolling_mean_sales_store_family\" \n",
    "    , lag(D7_rolling_mean_sales_store_family, 182) OVER (PARTITION BY store_nbr, family order by date asc) \"lag2_7D_rolling_mean_sales_store_family\" \n",
    "    from df\n",
    "    \"\"\").df() #\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_seasonality_data(df):\n",
    "    df_seasonality =db.sql(\"\"\"\n",
    "    with base as (\n",
    "       select family, year, weekofyear, sum(sales) OVER (PARTITION BY family, year, weekofyear) \"sales_qtrly\" from df_train \n",
    "       where date < '2017-07-01' --and weekofyear <> 53 \n",
    "    ), pivt as (\n",
    "    PIVOT base\n",
    "    ON year\n",
    "    USING avg(sales_qtrly)    \n",
    "    )\n",
    "    select * from pivt \n",
    "    \"\"\").df().sort_values(['weekofyear']) #.query(\"store_nbr== 1 and family=='EGGS'\")\n",
    "    df_seasonality.loc[:,'Row_Total'] = df_seasonality[['2013','2014','2015','2016']].sum(numeric_only=True, axis=1)/4\n",
    "    mean_mean_factor = np.mean(df_seasonality[\"Row_Total\"])\n",
    "    df_seasonality[\"scaled_seasonal_factor_weekly\"] = df_seasonality[\"Row_Total\"].apply(lambda x: x/mean_mean_factor)\n",
    "    df = db.sql(\"\"\"\n",
    "        select t.*, dfs.scaled_seasonal_factor_weekly from df t \n",
    "        join df_seasonality dfs on t.family=dfs.family and t.weekofyear = dfs.weekofyear     \n",
    "    \"\"\").df()#.query(\"store_nbr==1 and family=='EGGS'\")#.to_clipboard()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'store_nbr', 'family', 'onpromotion', 'month', 'year',\n",
       "       'day_of_week', 'day_of_month', 'quarter', 'weekofyear', 'payday',\n",
       "       'is_weekend', 'sales', 'cluster', 'type', 'state', 'city',\n",
       "       'holiday_type', 'oil_price', '7d_avg_oil_price', '90d_avg_oil_price',\n",
       "       '15d_avg_oil_price', 'oil_lag364', '7d_transactions_avg',\n",
       "       'number_of_holidays', 'is_national_holiday', 'earthquake_impact',\n",
       "       'is_holiday', 'W3_rolling_mean_sales_store_family_dayofweek',\n",
       "       'D7_rolling_mean_sales_store_family',\n",
       "       '15D_rolling_mean_sales_store_family',\n",
       "       'lag1_7D_rolling_mean_sales_store_family',\n",
       "       'lag2_7D_rolling_mean_sales_store_family',\n",
       "       'scaled_seasonal_factor_weekly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = prep_train_data(pd.read_csv('data/train.csv'))\n",
    "df_train = add_rolling_data(df_train)\n",
    "df_train = add_seasonality_data(df_train)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>is_national_holiday</th>\n",
       "      <th>earthquake_impact</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>W3_rolling_mean_sales_store_family_dayofweek</th>\n",
       "      <th>D7_rolling_mean_sales_store_family</th>\n",
       "      <th>15D_rolling_mean_sales_store_family</th>\n",
       "      <th>lag1_7D_rolling_mean_sales_store_family</th>\n",
       "      <th>lag2_7D_rolling_mean_sales_store_family</th>\n",
       "      <th>scaled_seasonal_factor_weekly</th>\n",
       "      <th>future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2538136</td>\n",
       "      <td>2016-11-28 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.25</td>\n",
       "      <td>358.50</td>\n",
       "      <td>368.3750</td>\n",
       "      <td>364.250</td>\n",
       "      <td>491.625</td>\n",
       "      <td>3.156493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2539918</td>\n",
       "      <td>2016-11-29 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.00</td>\n",
       "      <td>333.50</td>\n",
       "      <td>351.6250</td>\n",
       "      <td>364.625</td>\n",
       "      <td>487.375</td>\n",
       "      <td>3.156493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2541700</td>\n",
       "      <td>2016-11-30 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>800.00</td>\n",
       "      <td>321.25</td>\n",
       "      <td>336.7500</td>\n",
       "      <td>368.125</td>\n",
       "      <td>498.500</td>\n",
       "      <td>3.156493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2543482</td>\n",
       "      <td>2016-12-01 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>594.75</td>\n",
       "      <td>326.00</td>\n",
       "      <td>335.7500</td>\n",
       "      <td>380.000</td>\n",
       "      <td>510.750</td>\n",
       "      <td>3.156493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2545264</td>\n",
       "      <td>2016-12-02 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492.75</td>\n",
       "      <td>328.50</td>\n",
       "      <td>340.9375</td>\n",
       "      <td>403.875</td>\n",
       "      <td>503.875</td>\n",
       "      <td>3.156493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>3029395</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>3029396</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>3029397</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>3029398</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>3029399</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029400 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 date  store_nbr                      family  \\\n",
       "0      2538136  2016-11-28 00:00:00         25                    CLEANING   \n",
       "1      2539918  2016-11-29 00:00:00         25                    CLEANING   \n",
       "2      2541700  2016-11-30 00:00:00         25                    CLEANING   \n",
       "3      2543482  2016-12-01 00:00:00         25                    CLEANING   \n",
       "4      2545264  2016-12-02 00:00:00         25                    CLEANING   \n",
       "...        ...                  ...        ...                         ...   \n",
       "28507  3029395           2017-08-31          9                     POULTRY   \n",
       "28508  3029396           2017-08-31          9              PREPARED FOODS   \n",
       "28509  3029397           2017-08-31          9                     PRODUCE   \n",
       "28510  3029398           2017-08-31          9  SCHOOL AND OFFICE SUPPLIES   \n",
       "28511  3029399           2017-08-31          9                     SEAFOOD   \n",
       "\n",
       "       onpromotion  month    year  day_of_week  day_of_month  quarter  ...  \\\n",
       "0                7   11.0  2016.0          0.0          28.0      4.0  ...   \n",
       "1                5   11.0  2016.0          1.0          29.0      4.0  ...   \n",
       "2                9   11.0  2016.0          2.0          30.0      4.0  ...   \n",
       "3               14   12.0  2016.0          3.0           1.0      4.0  ...   \n",
       "4               14   12.0  2016.0          4.0           2.0      4.0  ...   \n",
       "...            ...    ...     ...          ...           ...      ...  ...   \n",
       "28507            1    NaN     NaN          NaN           NaN      NaN  ...   \n",
       "28508            0    NaN     NaN          NaN           NaN      NaN  ...   \n",
       "28509            1    NaN     NaN          NaN           NaN      NaN  ...   \n",
       "28510            9    NaN     NaN          NaN           NaN      NaN  ...   \n",
       "28511            0    NaN     NaN          NaN           NaN      NaN  ...   \n",
       "\n",
       "       is_national_holiday  earthquake_impact  is_holiday  \\\n",
       "0                      0.0                  0         0.0   \n",
       "1                      0.0                  0         0.0   \n",
       "2                      0.0                  0         0.0   \n",
       "3                      0.0                  0         0.0   \n",
       "4                      0.0                  0         0.0   \n",
       "...                    ...                ...         ...   \n",
       "28507                  NaN                NaN         NaN   \n",
       "28508                  NaN                NaN         NaN   \n",
       "28509                  NaN                NaN         NaN   \n",
       "28510                  NaN                NaN         NaN   \n",
       "28511                  NaN                NaN         NaN   \n",
       "\n",
       "       W3_rolling_mean_sales_store_family_dayofweek  \\\n",
       "0                                            486.25   \n",
       "1                                            495.00   \n",
       "2                                            800.00   \n",
       "3                                            594.75   \n",
       "4                                            492.75   \n",
       "...                                             ...   \n",
       "28507                                           NaN   \n",
       "28508                                           NaN   \n",
       "28509                                           NaN   \n",
       "28510                                           NaN   \n",
       "28511                                           NaN   \n",
       "\n",
       "       D7_rolling_mean_sales_store_family 15D_rolling_mean_sales_store_family  \\\n",
       "0                                  358.50                            368.3750   \n",
       "1                                  333.50                            351.6250   \n",
       "2                                  321.25                            336.7500   \n",
       "3                                  326.00                            335.7500   \n",
       "4                                  328.50                            340.9375   \n",
       "...                                   ...                                 ...   \n",
       "28507                                 NaN                                 NaN   \n",
       "28508                                 NaN                                 NaN   \n",
       "28509                                 NaN                                 NaN   \n",
       "28510                                 NaN                                 NaN   \n",
       "28511                                 NaN                                 NaN   \n",
       "\n",
       "      lag1_7D_rolling_mean_sales_store_family  \\\n",
       "0                                     364.250   \n",
       "1                                     364.625   \n",
       "2                                     368.125   \n",
       "3                                     380.000   \n",
       "4                                     403.875   \n",
       "...                                       ...   \n",
       "28507                                     NaN   \n",
       "28508                                     NaN   \n",
       "28509                                     NaN   \n",
       "28510                                     NaN   \n",
       "28511                                     NaN   \n",
       "\n",
       "      lag2_7D_rolling_mean_sales_store_family scaled_seasonal_factor_weekly  \\\n",
       "0                                     491.625                      3.156493   \n",
       "1                                     487.375                      3.156493   \n",
       "2                                     498.500                      3.156493   \n",
       "3                                     510.750                      3.156493   \n",
       "4                                     503.875                      3.156493   \n",
       "...                                       ...                           ...   \n",
       "28507                                     NaN                           NaN   \n",
       "28508                                     NaN                           NaN   \n",
       "28509                                     NaN                           NaN   \n",
       "28510                                     NaN                           NaN   \n",
       "28511                                     NaN                           NaN   \n",
       "\n",
       "       future  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "28507       Y  \n",
       "28508       Y  \n",
       "28509       Y  \n",
       "28510       Y  \n",
       "28511       Y  \n",
       "\n",
       "[3029400 rows x 36 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep test data \n",
    "entire_df = pd.concat([pd.read_csv('data/train.csv'), pd.read_csv('data/test.csv')])\n",
    "entire_df\n",
    "# test_df = prep_train_data(test_df)\n",
    "# test_df = add_rolling_data(test_df)\n",
    "# test_df = add_seasonality_data(test_df)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'store_nbr', \n",
    "             'onpromotion' , 'family'\n",
    "            #, 'cluster\n",
    "            #, 'day_of_week'                       \n",
    "            , 'W3_rolling_mean_sales_store_family_dayofweek'\n",
    "            , 'D7_rolling_mean_sales_store_family' #, '15D_rolling_mean_sales_store_family' \n",
    "            , \"7d_avg_oil_price\" , \"90d_avg_oil_price\" \n",
    "            #, \"15d_avg_oil_price\"\n",
    "            , \"number_of_holidays\"\n",
    "            , \"scaled_seasonal_factor_weekly\" \n",
    "            , \"oil_lag364\"\n",
    "            ,  \"lag1_7D_rolling_mean_sales_store_family\"\n",
    "            , \"lag2_7D_rolling_mean_sales_store_family\"\n",
    "    ]\n",
    "TARGET = 'sales' \n",
    "\n",
    "X_train, y_train = df_train[features], df_train['sales']\n",
    "#X_test, y_test = pjme_test[features], pjme_test['sales']\n",
    "import sklearn.metrics\n",
    "reg = XGBRegressor(n_estimators=20000, enable_categorical=True, early_stopping_rounds=15, eval_metric = 'rmsle', learning_rate = .3)\n",
    "reg.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "pjme_test['prediction_label'] = reg.predict(X_test) \n",
    "pjme_test['prediction_label'] = pjme_test['prediction_label'].apply(lambda x: 0 if x<0 else x)\n",
    "#pjme_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
